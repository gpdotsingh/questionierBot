which python              
/Users/gauravsingh/study/AI/DeependraBhaiyaproject/chunking/.venv/bin/python


(chunking) (base) gauravsingh@Gauravs-MacBook-Pro chunking % uv add -r requirements.txt

(chunking) (base) gauravsingh@Gauravs-MacBook-Pro chunking % uv init                   

(chunking) (base) gauravsingh@Gauravs-MacBook-Pro chunking % uv venv                   

(chunking) (base) gauravsingh@Gauravs-MacBook-Pro chunking % source .venv/bin/activate 

if I am creating below requirement prepre the project structure wrt to UV as I am going to use uv.

0- Data file where I will keep the data
0- corresponding Metadat or file definitions for data
1- Loader, load the files or text or xml 
2- Create the chunks
3- create embeddings from chunks
4 - Create the vector from embedding
5- Question splitter, read the questions from the input provided then split the questions from its intelligence using openai or ollama or deepseek or grok or anyother provider
Search the context from the yaml of metadata 
Split the questions in a way like if I have question which is going to have some dependednt question inside it then it will split the question meaningfully and also provide insight about how the questions  are dependednt on each other which one should be queried first and in response of which one is going to be key for another.
6- Orceshtrator, it will take questions from splitter prepare query for questions , if any set of subquestion or questions can be queried in parallel then it will prepare the query from chroma print them and execute the query either in parralel if , the output of one query is input for another then it will run the sub query and recall it as input from subquery with input as resul from sub query and master question.
7 - compiler, it will get result from orcehstrator and will make the response in humanised form.
8. Validator, it will validate the response from the compiler and question asked from input like in splitter if it doesn't make sence then it will refine the query and call splitter again. And in result gives the confidence score
9- Server.py which will wire all components and will be responsible to load the env, and provide all keys and model and llm provider to each module.





------------------------------------------

1- Load data 

python scripts/build_vectors.py
python scripts/query_vectors.py